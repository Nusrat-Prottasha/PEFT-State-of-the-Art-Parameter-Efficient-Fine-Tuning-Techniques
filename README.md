# PEFT-State-of-the-Art-Parameter-Efficient-Fine-Tuning-Techniques

## üöÄ Serial Adapters

- Parameter-Efficient Transfer Learning for NLP [[Paper](https://arxiv.org/abs/1902.00751)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/google-research/adapter-bert)

- AdapterHub: A Framework for Adapting Transformers [[Paper](https://arxiv.org/abs/2007.07779)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/adapterhub-a-framework-for-adapting)

- MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer [[Paper](https://arxiv.org/abs/2005.00052)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/mad-x-an-adapter-based-framework-for-multi)

- Cross-Lingual Transfer with Target Language-Ready Task Adapters [[Paper](https://aclanthology.org/2023.findings-acl.13.pdf)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/parovicm/tlr-adapters?tab=readme-ov-file)


## üöÄ Parallel Adapters

- UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling [[Paper](https://arxiv.org/pdf/2302.06605)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/UniAdapter/UniAdapter)

- UniPT: Universal Parallel Tuning for Transfer Learning with Efficient Parameter and Memory [[Paper](https://arxiv.org/pdf/2308.14316)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/Paranioar/UniPT)

- AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition [[Paper](https://arxiv.org/pdf/2205.13535)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/ShoufaChen/AdaptFormer)

- BERT and PALs: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning [[Paper](https://arxiv.org/pdf/1902.02671)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/AsaCooperStickland/Bert-n-Pals?tab=readme-ov-file)

- PEMT: Multi-Task Correlation Guided Mixture-of-Experts Enables Parameter-Efficient Transfer Learning [[Paper](https://arxiv.org/pdf/2402.15082)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/JachinLin2022/PEMT)

- Conditional Adapters: Parameter-efficient Transfer Learning with Fast Inference [[Paper](https://arxiv.org/pdf/2304.04947)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/conditional-adapters-parameter-efficient)


## üöÄ Hybrid Adapters

- AUTOPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning [[Paper](https://arxiv.org/pdf/2301.12132)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/cambridgeltl/autopeft)

- CROSS-MODAL ADAPTER: PARAMETER-EFFICIENT TRANSFER LEARNING APPROACH FOR VISION-LANGUAGE MODELS [[Paper](https://arxiv.org/pdf/2404.12588)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/cross-modal-adapter-parameter-efficient)

- EFFICIENT REMOTE SENSING WITH HARMONIZED TRANSFER LEARNING AND MODALITY ALIGNMENT [[Paper](https://arxiv.org/pdf/2404.18253)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/seekerhuang/HarMA?tab=readme-ov-file)

- MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval [[Paper](https://arxiv.org/pdf/2301.07868)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/zhangbw17/MV-Adapter)

- Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets [[Paper](https://arxiv.org/pdf/2208.07463)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/Hhhhhhao/Conv-Adapter)

## üöÄ Single Task

- VISION TRANSFORMER ADAPTER FOR DENSE PREDICTIONS [[Paper](https://arxiv.org/pdf/2205.08534)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/czczup/ViT-Adapter)

- Simple, Scalable Adaptation for Neural Machine Translation [[Paper](https://aclanthology.org/D19-1165.pdf)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/simple-scalable-adaptation-for-neural-machine)

## üöÄ Multi Task

- K-ADAPTER: Infusing Knowledge into Pre-Trained Models with Adapters [[Paper](https://arxiv.org/pdf/2002.01808)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/microsoft/K-Adapter)

- AdapterFusion: Non-Destructive Task Composition for Transfer Learning [[Paper](https://arxiv.org/pdf/2005.00247)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/adapterfusion-non-destructive-task)

- OrchMoE: Efficient Multi-Adapter Learning with Task-Skill Synergy [[Paper](https://arxiv.org/pdf/2401.10559)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)

- Multi-Head Adapter Routing for Cross-Task Generalization [[Paper](https://arxiv.org/pdf/2211.03831)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/microsoft/mttl)

- Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks [[Paper](https://arxiv.org/pdf/2106.04489)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/rabeehk/hyperformer)

- When MOE Meets LLMs: Parameter Efficient Fine-tuning for Multi-task Medical Applications [[Paper](https://arxiv.org/pdf/2310.18339)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/liuqidong07/MOELoRA-peft)

- LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models [[Paper](https://aclanthology.org/2023.emnlp-main.319.pdf)]
  ![arXiv](https://img.shields.io/badge/EMNLP-4a4a4a?style=flat&labelColor=4a4a4a&color=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/AGI-Edgerunners/LLM-Adapters)

- AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models [[Paper](https://arxiv.org/pdf/2302.07027)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/adaptersoup-weight-averaging-to-improve)


## üöÄ Continuous Prompting 

- Prefix-Tuning: Optimizing Continuous Prompts for Generation [[Paper](https://arxiv.org/pdf/2101.00190)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/XiangLi1999/PrefixTuning)

- PEDRO: Parameter-Efficient Fine-tuning with Prompt DEpenDent Representation MOdification [[Paper](https://www.arxiv.org/pdf/2409.17834)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)

- DEPT: Decomposed Prompt Tuning for Parameter-Efficient Fine-Tuning [[Paper](https://arxiv.org/pdf/2309.05173)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/ZhengxiangShi/DePT)

- P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks [[Paper](https://arxiv.org/pdf/2110.07602)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/THUDM/P-tuning-v2)

- Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models [[Paper](https://arxiv.org/pdf/2404.04522)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)

- PTR: Prompt Tuning with Rules for Text Classification [[Paper](https://arxiv.org/pdf/2105.11259)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/thunlp/PTR)

- Prefix-Propagation: Parameter-Efficient Tuning for Long Sequences [[Paper](https://web3.arxiv.org/pdf/2305.12086)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/MonliH/prefix-propagation)

- Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts [[Paper](https://arxiv.org/pdf/2210.11292)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/xyltt/LPT)

- OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning [[Paper](https://arxiv.org/pdf/2402.04129)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/jpmorganchase/ovor)


## üöÄ Discrete Prompt

- RLPROMPT: Optimizing Discrete Text Prompts with Reinforcement Learning [[Paper](https://arxiv.org/pdf/2205.12548)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/mingkaid/rl-prompt)

- SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations [[Paper](https://arxiv.org/pdf/2305.13235)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/AkihikoWatanabe/paper_notes/issues/1684)


## üöÄ Domain Specific Adaption (Natural Language Understanding)

- Prompt Tuning Strikes Back: Customizing Foundation Models with Low-Rank Prompt Adaptation [[Paper](https://arxiv.org/pdf/2405.15282)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/jabhinav/Prompt-Tuning-Strikes-Back-with-LOPA)

- InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural Language Understanding [[Paper](https://arxiv.org/pdf/2306.04933)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/infoprompt-information-theoretic-soft-prompt)

- PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization [[Paper](https://arxiv.org/pdf/2407.18078)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/ChrisIsKing/Parameter-Efficient-Personalization)

- IDPG: An Instance-Dependent Prompt Generation Method [[Paper](https://arxiv.org/pdf/2204.04497)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/CSerxy/IDPG)

- APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models [[Paper](https://aclanthology.org/2023.emnlp-main.567.pdf)]
  ![EMNLP](https://img.shields.io/badge/EMNLP-4a4a4a?style=flat&labelColor=4a4a4a&color=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/wgcban/apt)

- SMoP: Towards Efficient and Effective Prompt Tuning with Sparse Mixture-of-Prompts [[Paper](https://aclanthology.org/2023.emnlp-main.884.pdf)]
  ![EMNLP](https://img.shields.io/badge/EMNLP-4a4a4a?style=flat&labelColor=4a4a4a&color=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/jyjohnchoi/SMoP)

## üöÄ Task Specific Adaption

- The Power of Scale for Parameter-Efficient Prompt Tuning [[Paper](https://arxiv.org/pdf/2104.08691)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/mkshing/Prompt-Tuning)

- SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer [[Paper](https://arxiv.org/pdf/2110.07904)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/spot-better-frozen-model-adaptation-through)

- APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference [[Paper](https://arxiv.org/html/2401.12200v2)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)

- XPROMPT: Exploring the Extreme of Prompt Tuning [[Paper](https://arxiv.org/pdf/2210.04457)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/BD-MF/XPrompt?tab=readme-ov-file)

- Parameter Efficient Multi-task Fine-tuning by Learning to Transfer Token-wise Prompts [[Paper](https://aclanthology.org/2023.findings-emnlp.584.pdf)]
  ![EMNLP](https://img.shields.io/badge/EMNLP-4a4a4a?style=flat&labelColor=4a4a4a&color=4a4a4a)
  [![Code](https://img.shields.io/badge/üë©‚Äçüíª%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/mlwu22/TPT)


