# PEFT-State-of-the-Art-Parameter-Efficient-Fine-Tuning-Techniques

## ğŸš€ Serial Adapters

- Parameter-Efficient Transfer Learning for NLP [[Paper](https://arxiv.org/abs/1902.00751)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/google-research/adapter-bert)

- AdapterHub: A Framework for Adapting Transformers [[Paper](https://arxiv.org/abs/2007.07779)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/adapterhub-a-framework-for-adapting)

- MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer [[Paper](https://arxiv.org/abs/2005.00052)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/mad-x-an-adapter-based-framework-for-multi)

- Cross-Lingual Transfer with Target Language-Ready Task Adapters [[Paper](https://aclanthology.org/2023.findings-acl.13.pdf)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/parovicm/tlr-adapters?tab=readme-ov-file)


## ğŸš€ Parallel Adapters

- UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling [[Paper](https://arxiv.org/pdf/2302.06605)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/UniAdapter/UniAdapter)

- UniPT: Universal Parallel Tuning for Transfer Learning with Efficient Parameter and Memory [[Paper](https://arxiv.org/pdf/2308.14316)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/Paranioar/UniPT)

- AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition [[Paper](https://arxiv.org/pdf/2205.13535)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/ShoufaChen/AdaptFormer)

- BERT and PALs: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning [[Paper](https://arxiv.org/pdf/1902.02671)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/AsaCooperStickland/Bert-n-Pals?tab=readme-ov-file)

- PEMT: Multi-Task Correlation Guided Mixture-of-Experts Enables Parameter-Efficient Transfer Learning [[Paper](https://arxiv.org/pdf/2402.15082)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/JachinLin2022/PEMT)

- Conditional Adapters: Parameter-efficient Transfer Learning with Fast Inference [[Paper](https://arxiv.org/pdf/2304.04947)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/conditional-adapters-parameter-efficient)


## ğŸš€ Hybrid Adapters

- AUTOPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning [[Paper](https://arxiv.org/pdf/2301.12132)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/cambridgeltl/autopeft)

- CROSS-MODAL ADAPTER: PARAMETER-EFFICIENT TRANSFER LEARNING APPROACH FOR VISION-LANGUAGE MODELS [[Paper](https://arxiv.org/pdf/2404.18253)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://paperswithcode.com/paper/cross-modal-adapter-parameter-efficient)

- EFFICIENT REMOTE SENSING WITH HARMONIZED TRANSFER LEARNING AND MODALITY ALIGNMENT [[Paper](https://arxiv.org/pdf/2404.18253)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/seekerhuang/HarMA?tab=readme-ov-file)

- MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval [[Paper](https://arxiv.org/pdf/2301.07868)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/zhangbw17/MV-Adapter)

- Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets [[Paper](https://arxiv.org/pdf/2208.07463)]
  ![arXiv](https://img.shields.io/badge/arXiv-4a4a4a?style=flat&logo=arXiv&logoColor=white&labelColor=4a4a4a)
  [![Code](https://img.shields.io/badge/ğŸ‘©â€ğŸ’»%20Code-2962FF?style=flat&labelColor=2962FF&color=2962FF)](https://github.com/Hhhhhhao/Conv-Adapter)

